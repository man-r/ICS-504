{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16cca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from timeit import default_timer as timer \n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd04207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 6885\n",
      "    Root location: G:/My Drive/ICS504/github/ICS-504/download_images\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0000000000000000': 0,\n",
       " '0000000000000010': 1,\n",
       " '0000000000000100': 2,\n",
       " '0000000000000110': 3,\n",
       " '0000000000100000': 4,\n",
       " '0000000000100010': 5,\n",
       " '0000000000100100': 6,\n",
       " '0000000000100110': 7,\n",
       " '0000000001000000': 8,\n",
       " '0000000001000010': 9,\n",
       " '0000000001000100': 10,\n",
       " '0000000001100000': 11,\n",
       " '0000000001100010': 12,\n",
       " '0000001000000000': 13,\n",
       " '0000001000000010': 14,\n",
       " '0000001000000100': 15,\n",
       " '0000001000100000': 16,\n",
       " '0000001000100010': 17,\n",
       " '0010000000000000': 18,\n",
       " '0010000000000010': 19,\n",
       " '0010000000000100': 20,\n",
       " '0010000000000110': 21,\n",
       " '0010000000100000': 22,\n",
       " '0010000000100010': 23,\n",
       " '0010000000100110': 24,\n",
       " '0010000001000000': 25,\n",
       " '0010000001000100': 26,\n",
       " '0010000001100000': 27,\n",
       " '0010001000000000': 28,\n",
       " '0010001000000010': 29,\n",
       " '0010001000000100': 30,\n",
       " '0010001000000110': 31,\n",
       " '0010001000100000': 32,\n",
       " '0010001000100010': 33,\n",
       " '0010001001000000': 34,\n",
       " '0010001001000100': 35,\n",
       " '0010001001100000': 36,\n",
       " '0100000000000000': 37,\n",
       " '0100000000000010': 38,\n",
       " '0100000000000100': 39,\n",
       " '0100000000100000': 40,\n",
       " '0100000000100010': 41,\n",
       " '0100000001000000': 42,\n",
       " '0100000001000100': 43,\n",
       " '0100000001100000': 44,\n",
       " '0100001000000000': 45,\n",
       " '0100001000000010': 46,\n",
       " '0100001000100000': 47,\n",
       " '0110000000000000': 48,\n",
       " '0110000000000010': 49,\n",
       " '0110000000000100': 50,\n",
       " '0110000000000110': 51,\n",
       " '0110000000001000': 52,\n",
       " '0110000000100000': 53,\n",
       " '0110000000100010': 54,\n",
       " '0110000000100100': 55,\n",
       " '0110000000100110': 56,\n",
       " '0110000001000000': 57,\n",
       " '0110000001000010': 58,\n",
       " '0110000001100000': 59,\n",
       " '0110000001100010': 60,\n",
       " '0110001000000000': 61,\n",
       " '0110001000000010': 62,\n",
       " '0110001000000100': 63,\n",
       " '0110001000000110': 64,\n",
       " '0110001000100000': 65,\n",
       " '0110001000100010': 66,\n",
       " '0110001000100100': 67,\n",
       " '0110001001000000': 68,\n",
       " '0110001001100000': 69}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'G:/My Drive/ICS504/github/ICS-504/download_images'\n",
    "\n",
    "# Write transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),# Resize the images to 64x64\n",
    "    transforms.ToTensor() # Turn the image into a torch.Tensor\n",
    "])\n",
    "\n",
    "# loading training data\n",
    "train_data = datasets.ImageFolder(root=data_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "# loading test data\n",
    "# test_data = datasets.ImageFolder(root=data_dir, \n",
    "#                                  transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\")\n",
    "\n",
    "# Get class names as a list\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f536452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ## zero centering\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for images, _ in train_data:\n",
    "    mean += images.mean(dim=(1,2))\n",
    "    std += images.std(dim=(1,2))\n",
    "\n",
    "# Compute the mean and standard deviation of the pixel values for each channel\n",
    "mean /= len(train_data)\n",
    "std /= len(train_data)\n",
    "\n",
    "\n",
    "# mean = [0.5644, 0.5995, 0.6298]\n",
    "# std  = [0.1767, 0.1662, 0.2231]\n",
    "\n",
    "print(\"train mean\", mean)\n",
    "print('train std', std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(255, 255)),# Resize the images to 64x64\n",
    "    transforms.ToTensor() # Turn the image into a torch.Tensor\n",
    "    transforms.Normalize(\n",
    "        mean=mean,\n",
    "        std=std\n",
    "    )\n",
    "])\n",
    "\n",
    "# loading training data\n",
    "train_data = datasets.ImageFolder(root=data_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_subdata, val_subdata = random_split(train_data, [int(len(train_data)*0.8), len(train_data)-int(len(train_data)*0.8)])\n",
    "\n",
    "# Setup batch size and number of workers \n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "print(f\"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.\")\n",
    "\n",
    "# Create DataLoader's\n",
    "train_dataloader = DataLoader(train_subdata, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataloader = DataLoader(val_subdata, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "# test_dataloader = DataLoader(test_data, \n",
    "#                                     batch_size=BATCH_SIZE, \n",
    "#                                     shuffle=False, \n",
    "#                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataloader, val_dataloader#test_dataloader, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42326812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        #1st block CNN with 32 filters size 7x7 strid 1 no padding with relu activation function\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        #7th block fully connected NN \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=25088, out_features=496, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.Linear(in_features=4096, out_features=1024, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024,out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "        #8th block is included in the cross entropy \n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.features(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNmodel(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    i = 1\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        i = i+1\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f78e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          early_stop=0):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    past_val_loss=999999999\n",
    "    loss_count = 1\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        lr = 0.\n",
    "        weight_decay = 0.\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr = param_group['lr']\n",
    "            weight_decay = param_group['weight_decay']\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"lr: {lr:.4f} | \"\n",
    "            f\"weight_decay: {weight_decay:.4f} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        if(past_val_loss < test_loss):\n",
    "          loss_count = loss_count + 1\n",
    "\n",
    "        if(loss_count == early_stop):\n",
    "          print('early stop')\n",
    "          break #early stop\n",
    "        else:\n",
    "          loss_count = 1\n",
    "        past_val_loss = test_loss\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55eff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 61\n",
    "\n",
    "# Recreate an instance of the model\n",
    "model = CNNmodel(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() #include softmax\n",
    "adam_optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001,weight_decay=0)\n",
    "\n",
    "# Start the timer\n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0 \n",
    "model_results = train(model=model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=val_dataloader,\n",
    "                        optimizer=adam_optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "model_ft\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 5) # last arg here, # classes? -gw\n",
    "\n",
    "# model_ft = model_ft.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75beb255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
