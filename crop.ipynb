{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e205e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018160104751586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6885,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28823d7327964bbaa1f41e9db4647ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "** Crop Extractor for Project Sidewalk **\n",
    "\n",
    "Given label metadata from the Project Sidewalk database, this script will\n",
    "extract JPEG crops of the features that have been labeled. The required metadata\n",
    "may be obtained by running the SQL query in \"samples/getFullLabelList.sql\" on the\n",
    "Sidewalk database, and exporting the results in CSV format. You must supply the\n",
    "path to the CSV file containing this data below. You can find an example of what\n",
    "this file should look like in \"samples/labeldata.csv\".\n",
    "\n",
    "Additionally, you should have downloaded original panorama\n",
    "images from Street View using DownloadRunner.py. You will need to supply the\n",
    "path to the folder containing these files.\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import csv\n",
    "import GSVImage\n",
    "import fnmatch\n",
    "import logging\n",
    "from utilities import *\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib.pyplot import imshow, figure, gcf, gca, show\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Mark the center of the crop?\n",
    "mark_center = True\n",
    "\n",
    "logging.basicConfig(filename='crop.log', level=logging.DEBUG)\n",
    "\n",
    "try:\n",
    "    from xml.etree import cElementTree as ET\n",
    "except ImportError as e:\n",
    "    from xml.etree import ElementTree as ET\n",
    "\n",
    "def add_mark_to_image(x, y, img_path):\n",
    "    image = mpimg.imread(img_path)\n",
    "    pts = np.array([[x,y]])\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(pts[:, 0], pts[:, 1], marker=\"x\", color=\"red\", s=200)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def predict_crop_size(sv_image_y):\n",
    "    \"\"\"\n",
    "    # Calculate distance from point to image center\n",
    "    dist_to_center = math.sqrt((x-im_width/2)**2 + (y-im_height/2)**2)\n",
    "    # Calculate distance from point to center of left edge\n",
    "    dist_to_left_edge = math.sqrt((x-0)**2 + (y-im_height/2)**2)\n",
    "    # Calculate distance from point to center of right edge\n",
    "    dist_to_right_edge = math.sqrt((x - im_width) ** 2 + (y - im_height/2) ** 2)\n",
    "\n",
    "    min_dist = min([dist_to_center, dist_to_left_edge, dist_to_right_edge])\n",
    "\n",
    "    crop_size = (4.0/15.0)*min_dist + 200\n",
    "\n",
    "    print(\"Min dist was \"+str(min_dist))\n",
    "    \"\"\"\n",
    "    crop_size = 0\n",
    "    distance = max(0, 19.80546390 + 0.01523952 * sv_image_y)\n",
    "\n",
    "    if distance > 0:\n",
    "        crop_size = 8725.6 * (distance ** -1.192)\n",
    "    if crop_size > 1500 or distance == 0:\n",
    "        crop_size = 1500\n",
    "    if crop_size < 50:\n",
    "        crop_size = 50\n",
    "\n",
    "    return crop_size\n",
    "\n",
    "def make_single_crop(path_to_image, sv_image_x, sv_image_y, PanoYawDeg, output_filename, draw_mark=False):\n",
    "    \"\"\"\n",
    "    Makes a crop around the object of interest\n",
    "    :param path_to_image: where the GSV pano is stored\n",
    "    :param sv_image_x: position\n",
    "    :param sv_image_y: position\n",
    "    :param PanoYawDeg: heading\n",
    "    :param output_filename: name of file for saving\n",
    "    :param draw_mark: if a dot should be drawn in the centre of the object/image\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    im = Image.open(path_to_image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    im_width = im.size[0]\n",
    "    im_height = im.size[1]\n",
    "    print(im_width, im_height)\n",
    "\n",
    "    predicted_crop_size = predict_crop_size(sv_image_y)\n",
    "    crop_width = predicted_crop_size\n",
    "    crop_height = predicted_crop_size\n",
    "\n",
    "    print('x before scaling: ', sv_image_x)\n",
    "    print('y before scaling: ', sv_image_y)\n",
    "    # Work out scaling factor based on image dimensions\n",
    "    scaling_factor = im_width / 13312\n",
    "    sv_image_x *= scaling_factor\n",
    "    sv_image_y *= scaling_factor\n",
    "\n",
    "    print('x after scaling: ', sv_image_x)\n",
    "    print('y after scaling: ', sv_image_y)\n",
    "    \n",
    "    \n",
    "    x = ((float(PanoYawDeg) / 360) * im_width + sv_image_x) % im_width\n",
    "    y = im_height / 2 - sv_image_y\n",
    "\n",
    "    \n",
    "    print('x final: ', x)\n",
    "    print('y final: ', y)\n",
    "    \n",
    "    add_mark_to_image(x,y,path_to_image)\n",
    "    print('get_mark_location: ', get_mark_location(x,y,im_width,im_height))\n",
    "    \n",
    "    r = 10\n",
    "    if draw_mark:\n",
    "        draw.ellipse((x - r, y - r, x + r, y + r), fill=128)\n",
    "\n",
    "    print(\"Plotting at \" + str(x) + \",\" + str(y) + \" using yaw \" + str(PanoYawDeg))\n",
    "\n",
    "    print(x, y)\n",
    "    top_left_x = x - crop_width / 2\n",
    "    top_left_y = y - crop_height / 2\n",
    "    cropped_square = im.crop((top_left_x, top_left_y, top_left_x + crop_width, top_left_y + crop_height))\n",
    "    cropped_square.save(output_filename)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def bulk_extract_crops(path_to_db_export, path_to_gsv_scrapes, destination_dir, mark_label=False):\n",
    "    csv_file = open(path_to_db_export)\n",
    "    csv_f = csv.reader(csv_file)\n",
    "    counter = 0\n",
    "    no_metadata_fail = 0\n",
    "    no_pano_fail = 0\n",
    "    lables = []\n",
    "    for row in csv_f:\n",
    "        if counter == 0:\n",
    "            counter += 1\n",
    "            continue\n",
    "\n",
    "        pano_id = row[0]\n",
    "        sv_image_x = float(row[1])\n",
    "        sv_image_y = float(row[2])\n",
    "        label_type = int(row[3])\n",
    "        photographer_heading = float(row[4])\n",
    "        heading = float(row[5])\n",
    "        label_id = int(row[7])\n",
    "\n",
    "        pano_img_path = path_to_gsv_scrapes+'pano_'+pano_id + '.jpg'\n",
    "        print('pano_img_path is ',pano_img_path)\n",
    "        print(\"Photographer heading is \" + str(photographer_heading))\n",
    "        print(\"Viewer heading is \" + str(heading))\n",
    "        pano_yaw_deg = 180 - photographer_heading\n",
    "\n",
    "        print(\"Yaw:\" + str(pano_yaw_deg))\n",
    "\n",
    "        # Extract the crop\n",
    "        if os.path.exists(pano_img_path):\n",
    "            counter += 1\n",
    "            destination_folder = os.path.join(destination_dir, str(label_type))\n",
    "            if not os.path.isdir(destination_folder):\n",
    "                os.makedirs(destination_folder)\n",
    "\n",
    "            crop_destination = destination_dir+ str(label_type)+ str(label_id) + \".jpg\"\n",
    "\n",
    "            make_single_crop(pano_img_path, sv_image_x, sv_image_y, pano_yaw_deg, crop_destination, draw_mark=mark_label)\n",
    "            print(\"Successfully extracted crop to \" + str(label_id) + \".jpg\")\n",
    "            logging.info(str(label_id) + \".jpg\" + \" \" + pano_id + \" \" + str(sv_image_x)\n",
    "                         + \" \" + str(sv_image_y) + \" \" + str(pano_yaw_deg) + \" \" + str(label_id))\n",
    "            logging.info(\"---------------------------------------------------\")\n",
    "        else:\n",
    "            no_pano_fail += 1\n",
    "            print(\"Panorama image not found.\")\n",
    "            logging.warning(\"Skipped label id \" + str(label_id) + \" due to missing image.\")\n",
    "\n",
    "    print(\"Finished.\")\n",
    "    print(str(no_pano_fail) + \" extractions failed because panorama image was not found.\")\n",
    "    print(str(no_metadata_fail) + \" extractions failed because metadata was not found.\")\n",
    "\n",
    "def get_x_y_coord(path_to_image, sv_image_x, sv_image_y, PanoYawDeg):\n",
    "    \n",
    "    im = Image.open(path_to_image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    im_width = im.size[0]\n",
    "    im_height = im.size[1]\n",
    "    \n",
    "    predicted_crop_size = predict_crop_size(sv_image_y)\n",
    "    crop_width = predicted_crop_size\n",
    "    crop_height = predicted_crop_size\n",
    "\n",
    "    # Work out scaling factor based on image dimensions\n",
    "    scaling_factor = im_width / 13312\n",
    "    sv_image_x *= scaling_factor\n",
    "    sv_image_y *= scaling_factor\n",
    "\n",
    "    x = ((float(PanoYawDeg) / 360) * im_width + sv_image_x) % im_width\n",
    "    y = im_height / 2 - sv_image_y\n",
    "\n",
    "    \n",
    "    \n",
    "    return get_mark_location(x,y,im_width,im_height)\n",
    "    \n",
    "\n",
    "\n",
    "def get_mark_location(x,y, img_w, img_h):\n",
    "    diagonal1_coord_x1 = 0\n",
    "    diagonal1_coord_y1 = 0\n",
    "    diagonal1_coord_x2 = img_w\n",
    "    diagonal1_coord_y2 = img_h\n",
    "    \n",
    "    \n",
    "    diagonal2_coord_x1 = img_w\n",
    "    diagonal2_coord_y1 = 0\n",
    "    diagonal2_coord_x2 = 0\n",
    "    diagonal2_coord_y2 = img_h\n",
    "    \n",
    "    \n",
    "    diagonal1_slop = (float)(diagonal1_coord_y2-diagonal1_coord_y1)/(diagonal1_coord_x2-diagonal1_coord_x1)\n",
    "    diagonal2_slop = (float)(diagonal2_coord_y2-diagonal2_coord_y1)/(diagonal2_coord_x2-diagonal2_coord_x1)\n",
    "    \n",
    "    point_slop1 = (float)(y-diagonal1_coord_y1)/(x-diagonal1_coord_x1)\n",
    "    point_slop2 = (float)(y-diagonal2_coord_y1)/(x-diagonal2_coord_x1)\n",
    "    \n",
    "    above_d1 = False\n",
    "    above_d2 = False\n",
    "    \n",
    "    if(diagonal1_slop > point_slop1):\n",
    "        above_d1 = True\n",
    "    \n",
    "    if(diagonal2_slop > point_slop2):\n",
    "        above_d2 = True\n",
    "    \n",
    "    location = 'Q'\n",
    "    \n",
    "    if(above_d1 and above_d2):\n",
    "        location ='q1'\n",
    "    \n",
    "    elif(above_d1 and not above_d2):\n",
    "        location ='q2'\n",
    "    \n",
    "    elif(not above_d1 and not above_d2):\n",
    "        location ='q3'\n",
    "    \n",
    "    else:\n",
    "        location = 'q4'\n",
    "    \n",
    "    return location\n",
    "\n",
    "    \n",
    "# *****************************************\n",
    "# Update paths below                      *\n",
    "# *****************************************\n",
    "\n",
    "# Path to CSV data from database - Place in 'metadata'\n",
    "pano_list_path = './pano_list_path.csv'\n",
    "csv_export_path = \"./github/sidewalk-cv-assets19/new_old_dataset_csvs/Train.csv\"\n",
    "# Path to panoramas downloaded using DownloadRunner.py. Reference correct directory\n",
    "gsv_pano_path = \"./test/\"\n",
    "# Path to location for saving the crops\n",
    "destination_path = \"./crops/\"\n",
    "\n",
    "\n",
    "pano_list_df = pd.read_csv(pano_list_path)\n",
    "csv_f = pd.read_csv(csv_export_path)\n",
    "counter = 0\n",
    "no_metadata_fail = 0\n",
    "no_pano_fail = 0\n",
    "labels = []\n",
    "\n",
    "for pano_id in tqdm(pano_list_df['Pano_ID']):\n",
    "    df = csv_f.loc[csv_f['Pano_ID'] == pano_id]\n",
    "    curb_ramps_right = '0' \n",
    "    curb_ramps_left = '0'\n",
    "    curb_ramps_front = '0'\n",
    "    curb_ramps_back = '0'\n",
    "    \n",
    "    missing_curb_ramp_right = '0'\n",
    "    missing_curb_ramps_left = '0'\n",
    "    missing_curb_ramp_front = '0'\n",
    "    missing_curb_ramps_back = '0'\n",
    "    \n",
    "    \n",
    "    obstructions_right = '0'\n",
    "    obstructions_left = '0'\n",
    "    obstructions_front = '0'\n",
    "    obstructions_back = '0'\n",
    "    \n",
    "    surface_problems_right = '0'\n",
    "    surface_problems_left = '0'\n",
    "    surface_problems_front = '0'\n",
    "    surface_problems_back = '0'\n",
    "    \n",
    "\n",
    "    if os.path.exists('G:/My Drive/ICS504/github/ICS-504/download_images/'+pano_id+'.jpg'):\n",
    "        for i,row in df.iterrows():\n",
    "            \n",
    "            sv_image_x = float(row[1])\n",
    "            sv_image_y = float(row[2])\n",
    "            label_type = int(row[3])\n",
    "            photographer_heading = float(row[4])\n",
    "            heading = float(row[5])\n",
    "\n",
    "            pano_yaw_deg = 180 - photographer_heading\n",
    "\n",
    "            location = get_x_y_coord(pano_img_path, sv_image_x, sv_image_y, pano_yaw_deg)\n",
    "\n",
    "            if (label_type == 1 and location == 'q1'):\n",
    "                curb_ramps_front = '1'\n",
    "            elif (label_type == 1 and location == 'q2'):\n",
    "                curb_ramps_right = '1'\n",
    "            elif (label_type == 1 and location == 'q3'):\n",
    "                curb_ramps_bottom = '1'\n",
    "            elif (label_type == 1 and location == 'q4'):\n",
    "                curb_ramps_left = '1'\n",
    "\n",
    "            elif (label_type == 2 and location == 'q1'):\n",
    "                missing_curb_ramp_front = '1'\n",
    "            elif (label_type == 2 and location == 'q2'):\n",
    "                missing_curb_ramp_right = '1'\n",
    "            elif (label_type == 2 and location == 'q3'):\n",
    "                missing_curb_ramp_bottom = '1'\n",
    "            elif (label_type == 2 and location == 'q4'):\n",
    "                missing_curb_ramp_left = '1'\n",
    "\n",
    "            elif (label_type == 3 and location == 'q1'):\n",
    "                obstructions_front = '1'\n",
    "            elif (label_type == 3 and location == 'q2'):\n",
    "                obstructions_right = '1'\n",
    "            elif (label_type == 3 and location == 'q3'):\n",
    "                obstructions_bottom = '1'\n",
    "            elif (label_type == 3 and location == 'q4'):\n",
    "                obstructions_left = '1'\n",
    "\n",
    "            elif (label_type == 4 and location == 'q1'):\n",
    "                surface_problems_front = '1'\n",
    "            elif (label_type == 4 and location == 'q2'):\n",
    "                surface_problems_right = '1'\n",
    "            elif (label_type == 4 and location == 'q3'):\n",
    "                surface_problems_bottom = '1'\n",
    "            elif (label_type == 4 and location == 'q4'):\n",
    "                surface_problems_left = '1'\n",
    "\n",
    "        label = curb_ramps_right+curb_ramps_left+curb_ramps_front+curb_ramps_back+missing_curb_ramp_right+missing_curb_ramps_left+missing_curb_ramp_front+missing_curb_ramps_back+obstructions_right+obstructions_left+obstructions_front+obstructions_back+surface_problems_right+surface_problems_left+surface_problems_front+surface_problems_back    \n",
    "    else:\n",
    "        label = 'no image'\n",
    "        \n",
    "    labels.append(label)    \n",
    "# bulk_extract_crops('./Test.csv', gsv_pano_path, destination_path, mark_label=False)\n",
    "# crop_box_helper(gsv_pano_path, csv_export_path) # not tested and validated with new code\n",
    "\n",
    "pano_list_df['label'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "08091ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pano_list_df.head\n",
    "pano_list_df.to_csv('./pano_list_path3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69d0ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0010000000000000' '0000000000000010' '0000000001100000'\n",
      " '0000000001000000' '0000001000000000' '0000000000000000'\n",
      " '0110000000000000' '0100000000000000' '0100001000000000'\n",
      " '0100000001100000' '0000000000100000' '0000001000100000'\n",
      " '0000001000000010' '0010001000000000' '0010000000000010'\n",
      " '0110000000000010' '0000000001100010' '0100000001000000'\n",
      " '0010000000100000' '0000000000100010' '0110000000100010'\n",
      " '0010000001000000' '0000000000100100' '0110001000000000'\n",
      " '0110000001000010' '0000000000000100' '0100000000000100'\n",
      " '0110000000100000' '0010001001000100' '0010000001000100'\n",
      " '0100000001000100' '0110001000100010' '0010000000000100'\n",
      " '0010001000100000' '0100000000100000' '0010000001100000'\n",
      " '0010001000000010' '0100000000000010' '0110000000000100'\n",
      " '0000000001000100' '0110000001100000' '0010001001000000'\n",
      " '0110000001000000' '0110001000100000' '0000000000000110'\n",
      " '0110001000000110' '0100001000000010' '0100001000100000'\n",
      " '0000001000000100' '0100000000100010' '0010000000100010'\n",
      " '0010001000100010' '0110001001000000' '0000001000100010'\n",
      " '0110001001100000' '0000000001000010' '0110000001100010'\n",
      " '0000000000100110' '0110000000001000' '0010001001100000'\n",
      " '0010001000000100' '0110000000100100' '0110001000100100'\n",
      " '0010000000000110' '0010000000100110' '0010001000000110'\n",
      " '0110000000100110' '0110000000000110' '0110001000000010'\n",
      " '0110001000000100']\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019518613815307617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6885,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975f946083194c69859ff1bd12158dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong:  P2WxMntfQNLqOLx-mhfS4g\n",
      "creating dir:  0100001000000000\n",
      "creating dir:  0100000001100000\n",
      "creating dir:  0000000000100000\n",
      "creating dir:  0000001000100000\n",
      "creating dir:  0000001000000010\n",
      "creating dir:  0010001000000000\n",
      "creating dir:  0010000000000010\n",
      "creating dir:  0110000000000010\n",
      "creating dir:  0000000001100010\n",
      "creating dir:  0100000001000000\n",
      "creating dir:  0010000000100000\n",
      "creating dir:  0000000000100010\n",
      "creating dir:  0110000000100010\n",
      "creating dir:  0010000001000000\n",
      "creating dir:  0000000000100100\n",
      "creating dir:  0110001000000000\n",
      "creating dir:  0110000001000010\n",
      "creating dir:  0000000000000100\n",
      "creating dir:  0100000000000100\n",
      "creating dir:  0110000000100000\n",
      "creating dir:  0010001001000100\n",
      "creating dir:  0010000001000100\n",
      "creating dir:  0100000001000100\n",
      "creating dir:  0110001000100010\n",
      "creating dir:  0010000000000100\n",
      "creating dir:  0010001000100000\n",
      "creating dir:  0100000000100000\n",
      "creating dir:  0010000001100000\n",
      "creating dir:  0010001000000010\n",
      "creating dir:  0100000000000010\n",
      "creating dir:  0110000000000100\n",
      "creating dir:  0000000001000100\n",
      "creating dir:  0110000001100000\n",
      "creating dir:  0010001001000000\n",
      "creating dir:  0110000001000000\n",
      "creating dir:  0110001000100000\n",
      "creating dir:  0000000000000110\n",
      "creating dir:  0110001000000110\n",
      "creating dir:  0100001000000010\n",
      "creating dir:  0100001000100000\n",
      "creating dir:  0000001000000100\n",
      "creating dir:  0100000000100010\n",
      "creating dir:  0010000000100010\n",
      "creating dir:  0010001000100010\n",
      "creating dir:  0110001001000000\n",
      "creating dir:  0000001000100010\n",
      "creating dir:  0110001001100000\n",
      "creating dir:  0000000001000010\n",
      "creating dir:  0110000001100010\n",
      "creating dir:  0000000000100110\n",
      "creating dir:  0110000000001000\n",
      "creating dir:  0010001001100000\n",
      "creating dir:  0010001000000100\n",
      "creating dir:  0110000000100100\n",
      "creating dir:  0110001000100100\n",
      "creating dir:  0010000000000110\n",
      "creating dir:  0010000000100110\n",
      "creating dir:  0010001000000110\n",
      "creating dir:  0110000000100110\n",
      "creating dir:  0110000000000110\n",
      "creating dir:  0110001000000010\n",
      "creating dir:  0110001000000100\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(pano_list_df.label.unique())\n",
    "for i,row in tqdm(pano_list_df.iterrows(), total=pano_list_df.shape[0]):\n",
    "    old_file = row['path']\n",
    "    new_file = 'G:/My Drive/ICS504/github/ICS-504/download_images/'+row['label']+'/'+row['Pano_ID']+'.jpg'\n",
    "    if not os.path.isdir('G:/My Drive/ICS504/github/ICS-504/download_images/'+row['label']):\n",
    "        print('creating dir: ',row['label'])\n",
    "        os.makedirs('G:/My Drive/ICS504/github/ICS-504/download_images/'+row['label'])\n",
    "    \n",
    "    if os.path.exists(old_file):\n",
    "        try:\n",
    "            shutil.move(old_file, new_file)\n",
    "        except:\n",
    "            print(\"Something went wrong: \", row['Pano_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb2e8317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01999497413635254,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 51597,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec21e4d63d564e69ae5f67758fa61cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to CSV data from database - Place in 'metadata'\n",
    "pano_list_path = 'G:/My Drive/ICS504/github/ICS-504/download_images/pano_list.csv'\n",
    "csv_export_path = \"./github/sidewalk-cv-assets19/new_old_dataset_csvs/Val.csv\"\n",
    "# Path to panoramas downloaded using DownloadRunner.py. Reference correct directory\n",
    "gsv_pano_path = \"./test/\"\n",
    "# Path to location for saving the crops\n",
    "destination_path = \"./crops/\"\n",
    "\n",
    "\n",
    "pano_list_df = pd.read_csv(pano_list_path)\n",
    "csv_f = pd.read_csv(csv_export_path)\n",
    "counter = 0\n",
    "no_metadata_fail = 0\n",
    "no_pano_fail = 0\n",
    "labels = []\n",
    "\n",
    "for pano_id in tqdm(pano_list_df['Pano_ID']):\n",
    "    df = csv_f.loc[csv_f['Pano_ID'] == pano_id]\n",
    "    curb_ramps_right = '0' \n",
    "    curb_ramps_left = '0'\n",
    "    curb_ramps_front = '0'\n",
    "    curb_ramps_back = '0'\n",
    "    \n",
    "    missing_curb_ramp_right = '0'\n",
    "    missing_curb_ramps_left = '0'\n",
    "    missing_curb_ramp_front = '0'\n",
    "    missing_curb_ramps_back = '0'\n",
    "    \n",
    "    \n",
    "    obstructions_right = '0'\n",
    "    obstructions_left = '0'\n",
    "    obstructions_front = '0'\n",
    "    obstructions_back = '0'\n",
    "    \n",
    "    surface_problems_right = '0'\n",
    "    surface_problems_left = '0'\n",
    "    surface_problems_front = '0'\n",
    "    surface_problems_back = '0'\n",
    "    \n",
    "\n",
    "    if os.path.exists('G:/My Drive/ICS504/github/ICS-504/download_images/0000000000000000/'+pano_id+'.jpg'):\n",
    "        for i,row in df.iterrows():\n",
    "            \n",
    "            sv_image_x = float(row[1])\n",
    "            sv_image_y = float(row[2])\n",
    "            label_type = int(row[3])\n",
    "            photographer_heading = float(row[4])\n",
    "            heading = float(row[5])\n",
    "\n",
    "            pano_yaw_deg = 180 - photographer_heading\n",
    "\n",
    "            location = get_x_y_coord(pano_img_path, sv_image_x, sv_image_y, pano_yaw_deg)\n",
    "\n",
    "            if (label_type == 1 and location == 'q1'):\n",
    "                curb_ramps_front = '1'\n",
    "            elif (label_type == 1 and location == 'q2'):\n",
    "                curb_ramps_right = '1'\n",
    "            elif (label_type == 1 and location == 'q3'):\n",
    "                curb_ramps_bottom = '1'\n",
    "            elif (label_type == 1 and location == 'q4'):\n",
    "                curb_ramps_left = '1'\n",
    "\n",
    "            elif (label_type == 2 and location == 'q1'):\n",
    "                missing_curb_ramp_front = '1'\n",
    "            elif (label_type == 2 and location == 'q2'):\n",
    "                missing_curb_ramp_right = '1'\n",
    "            elif (label_type == 2 and location == 'q3'):\n",
    "                missing_curb_ramp_bottom = '1'\n",
    "            elif (label_type == 2 and location == 'q4'):\n",
    "                missing_curb_ramp_left = '1'\n",
    "\n",
    "            elif (label_type == 3 and location == 'q1'):\n",
    "                obstructions_front = '1'\n",
    "            elif (label_type == 3 and location == 'q2'):\n",
    "                obstructions_right = '1'\n",
    "            elif (label_type == 3 and location == 'q3'):\n",
    "                obstructions_bottom = '1'\n",
    "            elif (label_type == 3 and location == 'q4'):\n",
    "                obstructions_left = '1'\n",
    "\n",
    "            elif (label_type == 4 and location == 'q1'):\n",
    "                surface_problems_front = '1'\n",
    "            elif (label_type == 4 and location == 'q2'):\n",
    "                surface_problems_right = '1'\n",
    "            elif (label_type == 4 and location == 'q3'):\n",
    "                surface_problems_bottom = '1'\n",
    "            elif (label_type == 4 and location == 'q4'):\n",
    "                surface_problems_left = '1'\n",
    "\n",
    "        label = curb_ramps_right+curb_ramps_left+curb_ramps_front+curb_ramps_back+missing_curb_ramp_right+missing_curb_ramps_left+missing_curb_ramp_front+missing_curb_ramps_back+obstructions_right+obstructions_left+obstructions_front+obstructions_back+surface_problems_right+surface_problems_left+surface_problems_front+surface_problems_back    \n",
    "    else:\n",
    "        label = 'no image'\n",
    "        \n",
    "    labels.append(label)    \n",
    "# bulk_extract_crops('./Test.csv', gsv_pano_path, destination_path, mark_label=False)\n",
    "# crop_box_helper(gsv_pano_path, csv_export_path) # not tested and validated with new code\n",
    "\n",
    "pano_list_df['label2'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7704a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pano_list_df.to_csv('./pano_list_path5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc987d78",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpano_list_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:1843\u001b[0m, in \u001b[0;36mSeries.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\base.py:1047\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1045\u001b[0m             result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1047\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\algorithms.py:407\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    404\u001b[0m htable, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    406\u001b[0m table \u001b[38;5;241m=\u001b[39m htable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:4719\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:4666\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:1784\u001b[0m, in \u001b[0;36mNDFrame.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m objects are mutable, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthus they cannot be hashed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1787\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "print(pano_list_df.label2.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdc9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
